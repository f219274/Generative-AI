{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s73QQ_sL5Qas"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "import random\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Roman-Urdu-Poetry.csv\")  # Use the correct file name\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Normalize Unicode characters (removes accents and diacritics)\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
        "\n",
        "    # Remove unwanted characters except for basic punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.,?!]\", \"\", text)\n",
        "\n",
        "    # Remove dots within words (fix ja.ega -> jaega, ro.ega -> roega)\n",
        "    text = re.sub(r\"\\.(?=\\w)\", \"\", text)\n",
        "\n",
        "    # Replace multiple spaces and newlines with a single space\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to poetry column\n",
        "df[\"Poetry\"] = df[\"Poetry\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "MuidaYiU-n9D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Poetry'])\n",
        "sequences = tokenizer.texts_to_sequences(df['Poetry'])\n",
        "max_sequence_length = 20\n",
        "\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, min(len(seq), max_sequence_length)):\n",
        "        input_sequences.append(seq[:i+1])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "BzGoawWv-0ej"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length-1),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    LSTM(128),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "8NlNpN4O-7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a5e3a3-1d30-4830-db61-5cd4f57a200c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "model.save(\"poetry_model.h5\")"
      ],
      "metadata": {
        "id": "XEXeGZlH-64r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c33a1db-e1a4-42bb-cb2d-130b32993880"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.0430 - loss: 7.5122\n",
            "Epoch 2/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.0462 - loss: 6.4869\n",
            "Epoch 3/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.0432 - loss: 6.2877\n",
            "Epoch 4/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.0453 - loss: 6.1853\n",
            "Epoch 5/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.0511 - loss: 6.0793\n",
            "Epoch 6/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.0618 - loss: 6.0167\n",
            "Epoch 7/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.0649 - loss: 5.8911\n",
            "Epoch 8/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.0734 - loss: 5.8011\n",
            "Epoch 9/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.0856 - loss: 5.6704\n",
            "Epoch 10/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.0943 - loss: 5.5969\n",
            "Epoch 11/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.0984 - loss: 5.4781\n",
            "Epoch 12/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1027 - loss: 5.3923\n",
            "Epoch 13/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1101 - loss: 5.2678\n",
            "Epoch 14/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.1224 - loss: 5.1082\n",
            "Epoch 15/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.1274 - loss: 5.0133\n",
            "Epoch 16/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.1309 - loss: 4.9221\n",
            "Epoch 17/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.1445 - loss: 4.7980\n",
            "Epoch 18/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.1483 - loss: 4.6898\n",
            "Epoch 19/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1590 - loss: 4.5508\n",
            "Epoch 20/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.1673 - loss: 4.4263\n",
            "Epoch 21/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.1826 - loss: 4.2898\n",
            "Epoch 22/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1917 - loss: 4.1329\n",
            "Epoch 23/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.2085 - loss: 3.9897\n",
            "Epoch 24/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.2196 - loss: 3.8646\n",
            "Epoch 25/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.2415 - loss: 3.6741\n",
            "Epoch 26/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.2579 - loss: 3.5478\n",
            "Epoch 27/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.2715 - loss: 3.4325\n",
            "Epoch 28/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.2997 - loss: 3.2632\n",
            "Epoch 29/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.3164 - loss: 3.1600\n",
            "Epoch 30/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.3433 - loss: 3.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.3615 - loss: 2.8882\n",
            "Epoch 32/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.3903 - loss: 2.7462\n",
            "Epoch 33/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.4226 - loss: 2.5961\n",
            "Epoch 34/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.4403 - loss: 2.4710\n",
            "Epoch 35/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.4635 - loss: 2.3689\n",
            "Epoch 36/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.4872 - loss: 2.2508\n",
            "Epoch 37/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.5154 - loss: 2.1134\n",
            "Epoch 38/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.5443 - loss: 1.9989\n",
            "Epoch 39/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.5621 - loss: 1.8982\n",
            "Epoch 40/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.5862 - loss: 1.8005\n",
            "Epoch 41/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.6060 - loss: 1.7021\n",
            "Epoch 42/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.6273 - loss: 1.6070\n",
            "Epoch 43/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.6423 - loss: 1.5206\n",
            "Epoch 44/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.6647 - loss: 1.4215\n",
            "Epoch 45/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.6823 - loss: 1.3461\n",
            "Epoch 46/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.7028 - loss: 1.2662\n",
            "Epoch 47/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.7217 - loss: 1.1863\n",
            "Epoch 48/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.7375 - loss: 1.1319\n",
            "Epoch 49/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.7463 - loss: 1.0630\n",
            "Epoch 50/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.7653 - loss: 1.0062\n",
            "Epoch 51/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.7750 - loss: 0.9431\n",
            "Epoch 52/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.7976 - loss: 0.8659\n",
            "Epoch 53/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.7890 - loss: 0.8761\n",
            "Epoch 54/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8156 - loss: 0.7825\n",
            "Epoch 55/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8324 - loss: 0.7139\n",
            "Epoch 56/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.8420 - loss: 0.6762\n",
            "Epoch 57/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8475 - loss: 0.6471\n",
            "Epoch 58/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8494 - loss: 0.6314\n",
            "Epoch 59/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8580 - loss: 0.6099\n",
            "Epoch 60/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.8766 - loss: 0.5261\n",
            "Epoch 61/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8831 - loss: 0.5009\n",
            "Epoch 62/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8852 - loss: 0.4939\n",
            "Epoch 63/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.8855 - loss: 0.4813\n",
            "Epoch 64/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.8859 - loss: 0.4939\n",
            "Epoch 65/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9028 - loss: 0.4134\n",
            "Epoch 66/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9121 - loss: 0.3829\n",
            "Epoch 67/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9173 - loss: 0.3521\n",
            "Epoch 68/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9075 - loss: 0.3881\n",
            "Epoch 69/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9040 - loss: 0.3895\n",
            "Epoch 70/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9168 - loss: 0.3510\n",
            "Epoch 71/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9201 - loss: 0.3393\n",
            "Epoch 72/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9241 - loss: 0.3294\n",
            "Epoch 73/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9280 - loss: 0.3022\n",
            "Epoch 74/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9331 - loss: 0.2880\n",
            "Epoch 75/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9253 - loss: 0.3119\n",
            "Epoch 76/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9244 - loss: 0.2964\n",
            "Epoch 77/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9350 - loss: 0.2656\n",
            "Epoch 78/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9394 - loss: 0.2483\n",
            "Epoch 79/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9389 - loss: 0.2532\n",
            "Epoch 80/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9284 - loss: 0.2770\n",
            "Epoch 81/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9325 - loss: 0.2631\n",
            "Epoch 82/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9365 - loss: 0.2462\n",
            "Epoch 83/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9392 - loss: 0.2415\n",
            "Epoch 84/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9353 - loss: 0.2520\n",
            "Epoch 85/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9452 - loss: 0.2272\n",
            "Epoch 86/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9429 - loss: 0.2188\n",
            "Epoch 87/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9374 - loss: 0.2395\n",
            "Epoch 88/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9361 - loss: 0.2428\n",
            "Epoch 89/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9435 - loss: 0.2112\n",
            "Epoch 90/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9516 - loss: 0.1910\n",
            "Epoch 91/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9403 - loss: 0.2280\n",
            "Epoch 92/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9384 - loss: 0.2323\n",
            "Epoch 93/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9405 - loss: 0.2276\n",
            "Epoch 94/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9494 - loss: 0.1965\n",
            "Epoch 95/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9473 - loss: 0.2003\n",
            "Epoch 96/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9465 - loss: 0.1995\n",
            "Epoch 97/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9461 - loss: 0.2045\n",
            "Epoch 98/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9455 - loss: 0.2042\n",
            "Epoch 99/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9459 - loss: 0.2019\n",
            "Epoch 100/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9466 - loss: 0.2030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_poem(prompt, num_lines, words_per_line, temperature):\n",
        "    \"\"\"\n",
        "    Generates a poem based on the given prompt.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): The initial word or phrase to start the poem.\n",
        "    - num_lines (int): Number of lines in the generated poem.\n",
        "    - words_per_line (int): Number of words per line.\n",
        "    - temperature (float): Controls the randomness of predictions.\n",
        "\n",
        "    Returns:\n",
        "    - str: The generated poem.\n",
        "    \"\"\"\n",
        "    poem = []\n",
        "    current_word = prompt.lower()\n",
        "\n",
        "    for _ in range(num_lines):\n",
        "        line = current_word  # Start each line with the prompt word\n",
        "\n",
        "        for _ in range(words_per_line - 1):\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "\n",
        "            predictions = model.predict(token_list, verbose=0)[0]\n",
        "            predictions = np.log(predictions + 1e-10) / temperature\n",
        "            exp_preds = np.exp(predictions)\n",
        "            predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "            sorted_indices = np.argsort(predictions)[-5:]  # Top 5 words\n",
        "            possible_words = [tokenizer.index_word.get(idx, None) for idx in sorted_indices if idx in tokenizer.index_word]\n",
        "            possible_words = [word for word in possible_words if word is not None]\n",
        "\n",
        "            if possible_words:\n",
        "                word = random.choices(possible_words, weights=predictions[sorted_indices])[0]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "            line += \" \" + word\n",
        "            current_word = word\n",
        "\n",
        "        poem.append(line.capitalize())\n",
        "\n",
        "    return \"\\n\".join(poem)\n",
        "\n",
        "# Get user input\n",
        "prompt = input(\"Enter the prompt for the poem: \")\n",
        "num_lines = int(input(\"Enter the number of lines: \"))\n",
        "words_per_line = int(input(\"Enter the number of words per line: \"))\n",
        "temperature = float(input(\"Enter the temperature (e.g., 0.8 for creativity): \"))\n",
        "\n",
        "# Generate and print the poem\n",
        "poem = generate_poem(prompt, num_lines, words_per_line, temperature)\n",
        "print(\"\\nGenerated Poem:\\n\")\n",
        "print(poem)\n"
      ],
      "metadata": {
        "id": "ncKOKAg7-6dF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a732f6c-db02-4ac7-c60a-46aaa7c0602f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the prompt for the poem: tere husn k naam \n",
            "Enter the number of lines: 4\n",
            "Enter the number of words per line: 5\n",
            "Enter the temperature (e.g., 0.8 for creativity): 0.8\n",
            "\n",
            "Generated Poem:\n",
            "\n",
            "Tere husn k naam  ja raha hai nikharta\n",
            "Nikharta se duur kho jaegi\n",
            "Jaegi khamushi ki khushbu khuli\n",
            "Khuli ankhon men sapna jhankta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Load trained model\n",
        "model = load_model(\"poetry_model.h5\")\n",
        "\n",
        "df = pd.read_csv(\"/content/Roman-Urdu-Poetry.csv\")  # Use the correct file name\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Normalize Unicode characters (removes accents and diacritics)\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
        "\n",
        "    # Remove unwanted characters except for basic punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.,?!]\", \"\", text)\n",
        "\n",
        "    # Remove dots within words (fix ja.ega -> jaega, ro.ega -> roega)\n",
        "    text = re.sub(r\"\\.(?=\\w)\", \"\", text)\n",
        "\n",
        "    # Replace multiple spaces and newlines with a single space\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to poetry column\n",
        "df[\"Poetry\"] = df[\"Poetry\"].apply(clean_text)\n",
        "\n",
        "# Define sequence length\n",
        "max_sequence_length = 20  # Ensure it matches training\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Poetry'])\n",
        "sequences = tokenizer.texts_to_sequences(df['Poetry'])\n",
        "max_sequence_length = 20\n",
        "\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, min(len(seq), max_sequence_length)):\n",
        "        input_sequences.append(seq[:i+1])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n",
        "\n",
        "def generate_poem(prompt, num_lines, words_per_line, temperature):\n",
        "    poem = []\n",
        "    current_word = prompt.lower()\n",
        "\n",
        "    for _ in range(num_lines):\n",
        "        line = current_word\n",
        "\n",
        "        for _ in range(words_per_line - 1):\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "\n",
        "            predictions = model.predict(token_list, verbose=0)[0]\n",
        "            predictions = np.log(predictions + 1e-10) / temperature\n",
        "            exp_preds = np.exp(predictions)\n",
        "            predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "            sorted_indices = np.argsort(predictions)[-5:]\n",
        "            possible_words = [tokenizer.index_word.get(idx, None) for idx in sorted_indices if idx in tokenizer.index_word]\n",
        "            possible_words = [word for word in possible_words if word is not None]\n",
        "\n",
        "            if possible_words:\n",
        "                word = random.choices(possible_words, weights=predictions[sorted_indices])[0]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "            line += \" \" + word\n",
        "            current_word = word\n",
        "\n",
        "        poem.append(line.capitalize())\n",
        "\n",
        "    return \"\\n\".join(poem)\n",
        "\n",
        "# Define Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_poem,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter Prompt\"),\n",
        "        gr.Number(label=\"Number of Lines\", value=4, precision=0),\n",
        "        gr.Number(label=\"Words per Line\", value=5, precision=0),\n",
        "        gr.Slider(0.1, 2.0, value=0.8, label=\"Temperature\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Poem\"),\n",
        "    title=\"Roman Urdu Poetry Generator\",\n",
        "    description=\"Generate poetry based on a given prompt using an LSTM model.\"\n",
        ")\n",
        "\n",
        "# Launch app\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "QTjCdPCk7WzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "40e5de0b-be0a-42e4-d460-3dae81b0ed6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://13c9701246c5f3416a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://13c9701246c5f3416a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}